import streamlit as st
import sys
import asyncio
import json
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner
from agents.mcp import MCPServerStdio
from dotenv import load_dotenv
import os
import openai
import base64


load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

    
# Windows í˜¸í™˜ì„±ì˜¤ë¥˜ ë°©ì§€
if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# MCP ì„œë²„ ì„¤ì •
async def setup_mcp_servers():
    servers = []
    
    # mcp.json íŒŒì¼ì—ì„œ ì„¤ì • ì½ê¸°
    with open('mcp.json', 'r') as f:
        config = json.load(f)
    
    # mcp-kss ì„œë²„ì˜ íŒŒì´ì¬ ê²½ë¡œë¥¼ í˜„ì¬ ì‹¤í–‰ì¤‘ì¸ íŒŒì´ì¬ìœ¼ë¡œ ì§€ì •
    if 'mcp-kss' in config.get('mcpServers', {}):
        config['mcpServers']['mcp-kss']['command'] = sys.executable

    # êµ¬ì„±ëœ MCP ì„œë²„ë“¤ì„ ìˆœíšŒ
    for server_name, server_config in config.get('mcpServers', {}).items():
        mcp_server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", []),
                "env": os.environ
            },
            cache_tools_list=True,
            client_session_timeout_seconds= int(os.getenv("MCP_DELAY"))            
        )
        await mcp_server.connect()
        servers.append(mcp_server)            
    return servers

# ì—ì´ì „íŠ¸ ì„¤ì •
async def setup_agent():
    # ì„œë²„ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±
    mcp_servers = await setup_mcp_servers()
    
    agent = Agent(
        name="Assistant",
        instructions=open('instructions.txt', 'r', encoding='utf-8').read(),
        model= os.getenv("OPENAI_MODEL"),
        mcp_servers= mcp_servers
    )
    return agent,mcp_servers


# ë©”ì‹œì§€ ì²˜ë¦¬
async def process_user_message():
    try:
        agent, mcp_servers = await setup_agent()
        messages = st.session_state.chat_history

        result = Runner.run_streamed(agent, input=messages)

        response_text = ""
        placeholder = st.empty()

        async for event in result.stream_events():           
            # LLM ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë°
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                response_text += event.data.delta or ""
                with placeholder.container():
                    with st.chat_message("assistant"):
                        st.markdown(response_text)

            # ë„êµ¬ ì´ë²¤íŠ¸ì™€ ë©”ì‹œì§€ ì™„ë£Œ ì²˜ë¦¬
            elif event.type == "run_item_stream_event":
                item = event.item

                if item.type == "tool_call_item":
                    tool_name = item.raw_item.name
                    st.toast(f"ğŸ›  ë„êµ¬ í™œìš©: `{tool_name}`")
          

        st.session_state.chat_history.append({
            "role": "assistant",
            "content": response_text
        })
        # ëª…ì‹œì  ì¢…ë£Œ (streamlitì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
        for server in mcp_servers:
            await server.__aexit__(None, None, None)
    except asyncio.CancelledError:
        pass

# Streamlit UI ë©”ì¸
def main():        
    st.set_page_config(page_icon="ğŸ”·")

    # style.css ì ìš©
    with open("style.css",encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

    # ë¡œê³  í‘œì‹œ
    st.markdown(
        f'<div style="text-align: left;"><img src="data:image/png;base64,{base64.b64encode(open("surplusglobal_logo.png", "rb").read()).decode()}" width="300"></div>',
        unsafe_allow_html=True
    )        

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    
    st.title(f"{os.getenv('KSS_ID').upper()}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!")
    st.divider()   
    st.caption(f"Account ìƒì„±, ì—…ë°ì´íŠ¸, ì‚­ì œ, ì¡°íšŒ ë“± ìš”ì²­í•´ì£¼ì„¸ìš”! - AI Model: ({os.getenv('OPENAI_MODEL')})")
    if os.getenv('KSS_SERVER') == '1':
        st.caption("âš ï¸ ì£¼ì˜: ë©”ì¸ ì„œë²„ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
    elif os.getenv('KSS_SERVER') == '2':
        st.caption("â„¹ï¸ ì•Œë¦¼: ê°œë°œ ì„œë²„ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    for m in st.session_state.chat_history:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("ì˜¤ëŠ˜ ì–´ë–¤ ë„ì›€ì„ ë“œë¦´ê¹Œìš”?")

    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        # ë¹„ë™ê¸° ì‘ë‹µ ì²˜ë¦¬
        with st.spinner("AIê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                asyncio.run(process_user_message())
            except openai.APIError as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
